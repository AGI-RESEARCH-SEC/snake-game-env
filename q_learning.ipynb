{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzXa5UMIg6Rz"
      },
      "source": [
        "## Our Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "tpp4V0vuHXjP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# Define the maze\n",
        "maze = [\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, 1, 1, 1, 1, 0, 1, 1, 1],\n",
        "    [1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
        "    [1, 1, 1, 1, 1, 0, 1, 1, 1],\n",
        "    [1, 1, 1, 1, 1, 0, 1, 1, 1],\n",
        "    [1, 1, 1, 1, 1, 0, 1, 1, 1],\n",
        "    [1, 1, 1, 1, 1, 0, 1, 1, 1],\n",
        "    [1, 1, 1, 1, 1, 0, 1, 1, 1],\n",
        "    [1, 1, 1, 1, 1, 0, 1, 1, 1],\n",
        "    [1, 1, 1, 0, 0, 1, 1, 1, 1],\n",
        "    [1, 1, 1, 0, 0, 1, 1, 1, 1],\n",
        "    [1, 1, 1, 0, 0, 1, 1, 1, 1],\n",
        "    [1, 1, 1, 0, 0, 1, 1, 1, 1],\n",
        "    [1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
        "]\n",
        "source = (2,8)\n",
        "destination = (13,8)\n",
        "\n",
        "# Define the maze\n",
        "maze = np.array([\n",
        "    [1, 1, 0, 1],\n",
        "    [1, 1, 0, 0],\n",
        "    [1, 1, 0, 1],\n",
        "    [1, 0, 0, 1],\n",
        "    [1, 0, 0, 0]\n",
        "])\n",
        "source = (1,3)\n",
        "destination = (4,3)\n",
        "facing = \"left\"\n",
        "\n",
        "# Obstacle Avoidance\n",
        "maze = np.array([\n",
        "    [1, 1, 1, 1],\n",
        "    [1, 1, 0, 1],\n",
        "    [1, 0, 0, 1],\n",
        "    [1, 0, 1, 1],\n",
        "    [1, 0, 0, 1],\n",
        "    [1, 1, 0, 0],\n",
        "    [1, 1, 1, 1]\n",
        "])\n",
        "source = (1,2)\n",
        "destination = (5,3)\n",
        "facing = \"down\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0gs7UlIWqG4",
        "outputId": "5c8f0a4c-6f5f-4778-e829-9725d16df06c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Binary: 101\n",
            "Decimal: 5\n"
          ]
        }
      ],
      "source": [
        "def binary_to_decimal(binary):\n",
        "    decimal = int(binary, 2)\n",
        "    return decimal\n",
        "\n",
        "# Example usage:\n",
        "binary_number = \"101\"\n",
        "decimal_value = binary_to_decimal(binary_number)\n",
        "print(\"Binary:\", binary_number)\n",
        "print(\"Decimal:\", decimal_value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAFT67Y3K5XB",
        "outputId": "3ff15f5e-1a24-4469-c551-a78ea3968ee7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1, 0, 1), 5)"
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_current_state(maze, current_location, facing):\n",
        "    row, col = current_location\n",
        "    # Calculate the next location based on the facing direction\n",
        "    if facing == 'up':\n",
        "        front_row, front_col = row - 1, col\n",
        "        left_row, left_col = row, col - 1\n",
        "        right_row, right_col = row, col + 1\n",
        "        # Check if there is a path to the left\n",
        "        left_value = 0 if left_col > 0 and maze[left_row][left_col] == 0 else 1\n",
        "        # Check if there is a path to the right\n",
        "        right_value = 0 if right_col < len(maze[0]) and maze[right_row][right_col] == 0 else 1\n",
        "        # Check if there is a path to the front\n",
        "        front_value = 0 if front_row > 0 and maze[front_row][front_col] == 0 else 1\n",
        "        # Check if there is an obstacle in front\n",
        "    elif facing == 'down':\n",
        "        front_row, front_col = row + 1, col\n",
        "        left_row, left_col = row, col + 1\n",
        "        right_row, right_col = row, col - 1\n",
        "        # Check if there is a path to the left\n",
        "        left_value = 0 if left_col < len(maze[0]) and maze[left_row][left_col] == 0 else 1\n",
        "        # Check if there is a path to the right\n",
        "        right_value = 0 if right_col > 0 and maze[right_row][right_col] == 0 else 1\n",
        "        # Check if there is a path to the front\n",
        "        front_value = 0 if front_row < len(maze) and maze[front_row][front_col] == 0 else 1\n",
        "    elif facing == 'left':\n",
        "        front_row, front_col = row, col - 1\n",
        "        left_row, left_col = row + 1, col\n",
        "        right_row, right_col = row - 1, col\n",
        "        # Check if there is a path to the left\n",
        "        left_value = 0 if left_row < len(maze) and maze[left_row][left_col] == 0 else 1\n",
        "        # Check if there is a path to the right\n",
        "        right_value = 0 if right_row > 0 and maze[right_row][right_col] == 0 else 1\n",
        "        # Check if there is a path to the front\n",
        "        front_value = 0 if front_col > 0 and maze[front_row][front_col] == 0 else 1\n",
        "    elif facing == 'right':\n",
        "        front_row, front_col = row, col + 1\n",
        "        left_row, left_col = row - 1, col\n",
        "        right_row, right_col = row + 1, col\n",
        "        # Check if there is a path to the left\n",
        "        left_value = 0 if left_row >0 and maze[left_row][left_col] == 0 else 1\n",
        "        # Check if there is a path to the right\n",
        "        right_value = 0 if right_row <  len(maze) and maze[right_row][right_col] == 0 else 1\n",
        "        # Check if there is a path to the front\n",
        "        front_value = 0 if front_col <  len(maze[0]) and maze[front_row][front_col] == 0 else 1\n",
        "    return (left_value, right_value, front_value), binary_to_decimal(str(left_value) + str(right_value) + str(front_value))\n",
        "\n",
        "# Example usage:\n",
        "# current_location = (2, 8)  # Example starting location\n",
        "current_location = (1, 3)  # Example starting location\n",
        "# facing_direction = 'up'    # Example starting facing direction\n",
        "get_current_state(maze, current_location, facing='up') # output: [0, 1, 1]<binary>, 3 <decimal>\n",
        "get_current_state(maze, current_location, facing='left') # output: [0, 1, 1]<binary>, 6 <decimal>\n",
        "get_current_state(maze, current_location, facing='right') # output: [1, 1, 1]<binary>, 7 <decimal>\n",
        "get_current_state(maze, current_location, facing='down') # output: [1, 0, 1] <binary> 5 <decimal>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMNqRp_gV18m",
        "outputId": "c67a23a7-78be-41fd-e380-5aa529d08a8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New Coordinates: (0, 0)\n",
            "New Facing Direction: left\n"
          ]
        }
      ],
      "source": [
        "def is_valid_coords(maze, coordinates):\n",
        "    x, y = coordinates\n",
        "    if (x>=0) and (x < len(maze)) and (y > 0) and (y < len(maze[0])) and maze[x][y]==0:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def move(maze, facing, action, current_coordinates, move_forward_on_turn=True):\n",
        "    '''\n",
        "      move_forward_on_turn=True makes it move forward towards direction of turn on every turn action.\n",
        "    '''\n",
        "    x, y = current_coordinates\n",
        "    new_facing = facing\n",
        "    new_coordinates = current_coordinates\n",
        "\n",
        "    # Perform the chosen action\n",
        "    if action == 0:\n",
        "      action = \"left\"\n",
        "    elif action == 1:\n",
        "      action = \"right\"\n",
        "    elif action == 2:\n",
        "      action = \"forward\"\n",
        "    elif action not in [\"left\", \"right\", \"forward\"]:\n",
        "      raise ValueError(f\"Amigo! action is not supposed to be \\\"{action}\\\". it is either of [left, right, forward]\")  # Raises a ValueError\n",
        "\n",
        "    if action == 'left':\n",
        "        if facing == 'up':\n",
        "            new_facing = 'left'\n",
        "        elif facing == 'down':\n",
        "            new_facing = 'right'\n",
        "        elif facing == 'left':\n",
        "            new_facing = 'down'\n",
        "        elif facing == 'right':\n",
        "            new_facing = 'up'\n",
        "        # new_coordinates = current_coordinates\n",
        "    elif action == 'right':\n",
        "        if facing == 'up':\n",
        "            new_facing = 'right'\n",
        "        elif facing == 'down':\n",
        "            new_facing = 'left'\n",
        "        elif facing == 'left':\n",
        "            new_facing = 'up'\n",
        "        elif facing == 'right':\n",
        "            new_facing = 'down'\n",
        "        # new_coordinates = current_coordinates\n",
        "    if move_forward_on_turn:\n",
        "        facing = new_facing\n",
        "    if action == \"forward\" or move_forward_on_turn:\n",
        "        if facing == 'up':\n",
        "            new_coordinates = (x - 1, y)\n",
        "        elif facing == 'down':\n",
        "            new_coordinates = (x + 1, y)\n",
        "        elif facing == 'left':\n",
        "            new_coordinates = (x, y - 1)\n",
        "        elif facing == 'right':\n",
        "            new_coordinates = (x, y + 1)\n",
        "        if not is_valid_coords(maze, new_coordinates):\n",
        "            new_coordinates = current_coordinates\n",
        "        # new_facing = facing\n",
        "    return new_coordinates, new_facing\n",
        "\n",
        "# Example usage:\n",
        "current_facing = 'up'      # Example current facing action\n",
        "action = 'left'  # Example rotation action ('left' or 'right')\n",
        "\n",
        "current_coordinates = (0, 0)  # Example starting coordinates\n",
        "new_coordinates, new_facing = move(maze, current_facing, action, current_coordinates)\n",
        "\n",
        "print(\"New Coordinates:\", new_coordinates)\n",
        "print(\"New Facing Direction:\", new_facing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "93hAdkjxfiP4"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "def display(maze, source, destination, current_position, path=None):\n",
        "    clear_output()\n",
        "    for i in range(len(maze)):\n",
        "        for j in range(len(maze[0])):\n",
        "            if (i, j) == source:\n",
        "                print('S', end=' ')\n",
        "            elif (i, j) == destination:\n",
        "                print('D', end=' ')\n",
        "            elif (i, j) == current_position:\n",
        "                print('C', end=' ')\n",
        "            elif path and (i, j) in path:\n",
        "                print('*', end=' ')  # Mark the path with '*'\n",
        "            elif maze[i][j] == 1:\n",
        "                print('#', end=' ')\n",
        "            else:\n",
        "                print('.', end=' ')\n",
        "        print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mtHLTGSgKc8"
      },
      "source": [
        "## Training Q-network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DeZVQS_RdnE",
        "outputId": "a2f23f6e-973c-46c8-a271-112941d97cfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# # # # \n",
            "# # S # \n",
            "# * * # \n",
            "# * # # \n",
            "# * * # \n",
            "# # * * \n",
            "# # # D \n",
            "path: len.8 [(1, 2), (2, 2), (2, 1), (3, 1), (4, 1), (4, 2), (5, 2), (5, 3)]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define Q-learning parameters\n",
        "num_actions = 4  # Up, Down, Left, Right\n",
        "learning_rate = 0.1\n",
        "discount_factor = 0.9\n",
        "exploration_rate = 0.1\n",
        "exploration_rate_decay = .85\n",
        "num_episodes = 1000\n",
        "\n",
        "# Define the number of states and actions\n",
        "num_states = 2 ** 3  # 3 binary inputs\n",
        "num_actions = 3      # left, right, forward\n",
        "iteration_path_len_data = []\n",
        "\n",
        "\n",
        "# Initialize Q-table with random values\n",
        "q_values = np.zeros((num_states, num_actions))\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "    # state = (0, 0)  # Starting position\n",
        "    current_coordinates = source\n",
        "    facing = \"left\" # For maze 2\n",
        "    facing = \"down\" # For maze 3\n",
        "    state_binary, state = get_current_state(maze, current_coordinates, facing)\n",
        "    path = [current_coordinates]\n",
        "\n",
        "    # while state != (maze.shape[0] - 1, maze.shape[1] - 1):  # Continue until reaching the goal\n",
        "    while current_coordinates != destination:\n",
        "        # Choose an action using epsilon-greedy strategy\n",
        "        if np.random.rand() < exploration_rate:\n",
        "            action = np.random.choice(num_actions)   # action is one of [0, 1, 2]\n",
        "        else:\n",
        "            action = np.argmax(q_values[state])      # action is one of [0, 1, 2]\n",
        "        new_coordinates, new_facing = move(maze, facing, action, current_coordinates)\n",
        "        new_state_binary, new_state = get_current_state(maze, new_coordinates, new_facing)\n",
        "\n",
        "\n",
        "        # Update Q-value using the Bellman equation\n",
        "        reward = -1 if maze[new_coordinates[0], new_coordinates[1]] == 0 else -5  # Penalize hitting a wall\n",
        "        reward = +2 if new_coordinates == destination else reward # Reward for reaching destination\n",
        "        q_values[state, action] += learning_rate * (\n",
        "                reward + discount_factor * np.max(q_values[new_state]) - q_values[state, action])\n",
        "\n",
        "        # Move to the new state\n",
        "        facing = new_facing\n",
        "        current_coordinates = new_coordinates\n",
        "        state = new_state\n",
        "        path.append(current_coordinates)\n",
        "    iteration_path_len_data.append([episode, len(path)])\n",
        "\n",
        "    # Decrease the exploration rate\n",
        "    exploration_rate *= exploration_rate_decay\n",
        "    if episode % 100 == 0:\n",
        "        display(maze=maze, path=path, source = source, destination= (maze.shape[0] - 1, maze.shape[1] - 1), current_position=(maze.shape[0] - 1, maze.shape[1] - 1))\n",
        "        print(f'{episode} path: len.{len(path)} {path}')\n",
        "\n",
        "print(\"Training complete!\")\n",
        "# visualize_path(path)\n",
        "display(maze=maze, path=path, source = source, destination= (maze.shape[0] - 1, maze.shape[1] - 1), current_position=(maze.shape[0] - 1, maze.shape[1] - 1))\n",
        "print(f'path: len.{len(path)} {path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "JSUNRvUaDTg4",
        "outputId": "cdf096e3-8367-4596-98e5-739a2a452543"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Your data in the format: [ [iteration-1, length-1], [iteration-2, length-2], ... ]\n",
        "# data = [[1, 10], [2, 15], [3, 20], [4, 25]]\n",
        "data = iteration_path_len_data\n",
        "\n",
        "# Extracting iterations and lengths into separate lists\n",
        "iterations, lengths = zip(*data)\n",
        "\n",
        "# Plotting the data\n",
        "plt.plot(iterations, lengths, marker='o', linestyle='-')\n",
        "plt.title('Iteration vs Length')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Length')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOYRP-RfgM5F"
      },
      "source": [
        "# Using Trained Q-Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7K7bcCgCgXeW",
        "outputId": "76d8a11d-7461-44f6-9f02-b4b49ef10fa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# # # # \n",
            "# # S # \n",
            "# * * # \n",
            "# * # # \n",
            "# * * # \n",
            "# # * * \n",
            "# # # D \n",
            "path: len.8 [(1, 2), (2, 2), (2, 1), (3, 1), (4, 1), (4, 2), (5, 2), (5, 3)]\n"
          ]
        }
      ],
      "source": [
        "source  = source\n",
        "destination  = destination\n",
        "\n",
        "current_coordinates = source\n",
        "facing = \"left\" # For maze 2\n",
        "facing = \"down\" # For maze 3\n",
        "state_binary, state = get_current_state(maze, current_coordinates, facing)\n",
        "path = [current_coordinates]\n",
        "\n",
        "# while state != (maze.shape[0] - 1, maze.shape[1] - 1):  # Continue until reaching the goal\n",
        "while current_coordinates != destination:\n",
        "    # Choose an action using epsilon-greedy strategy\n",
        "    # if np.random.rand() < exploration_rate:\n",
        "    #     action = np.random.choice(num_actions)\n",
        "    # else:\n",
        "    action = np.argmax(q_values[state])\n",
        "\n",
        "    new_coordinates, new_facing = move(maze, facing, action, current_coordinates)\n",
        "    new_state_binary, new_state = get_current_state(maze, new_coordinates, new_facing)\n",
        "\n",
        "    # Update Q-value using the Bellman equation\n",
        "    # reward = -1 if maze[new_coordinates[0], new_coordinates[1]] == 0 else -5  # Penalize hitting a wall\n",
        "    # reward = +5 if new_coordinates == destination else reward # Reward for reaching destination\n",
        "    # q_values[state, action] += learning_rate * (\n",
        "    #         reward + discount_factor * np.max(q_values[new_state]) - q_values[state, action])\n",
        "\n",
        "    # Move to the new state\n",
        "    facing = new_facing\n",
        "    current_coordinates = new_coordinates\n",
        "    state = new_state\n",
        "    path.append(current_coordinates)\n",
        "    # print(len(path))\n",
        "    display(maze=maze, path=path, source = source, destination= (maze.shape[0] - 1, maze.shape[1] - 1), current_position=(maze.shape[0] - 1, maze.shape[1] - 1))\n",
        "\n",
        "# Decrease the exploration rate\n",
        "exploration_rate *= exploration_rate_decay\n",
        "if episode % 100 == 0:\n",
        "    display(maze=maze, path=path, source = (0,0), destination= (maze.shape[0] - 1, maze.shape[1] - 1), current_position=(maze.shape[0] - 1, maze.shape[1] - 1))\n",
        "\n",
        "print(\"Training complete!\")\n",
        "# visualize_path(path)\n",
        "display(maze=maze, path=path, source = source, destination= (maze.shape[0] - 1, maze.shape[1] - 1), current_position=(maze.shape[0] - 1, maze.shape[1] - 1))\n",
        "print(f'path: len.{len(path)} {path}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fP5vRBZT-w0o"
      },
      "source": [
        "## Maze-2 Q-values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pzHjBCbrgBWx",
        "outputId": "b47dd3e4-2a83-446f-c96c-9bad0cda958c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# Maze-3\\n'"
            ]
          },
          "execution_count": 166,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Maze-2 Q-Values\n",
        "q_values\n",
        "'''\n",
        "# Maze-2\n",
        "array([[-0.14567543,  0.02899212, -0.26580594],\n",
        "       [15.50059371, -0.15679   , -0.57513834],\n",
        "       [-0.5       , -0.76106002, 19.25654426],\n",
        "       [16.33088984, -2.59484078, -2.47422423],\n",
        "       [-0.85218008, -0.70064572, 12.95053434],\n",
        "       [-2.28421257, -2.77678508, -2.6859972 ],\n",
        "       [-1.61504568, -1.84850008, 12.09657983],\n",
        "       [-2.71166051, -3.13316787, -3.18291114]])\n",
        "'''\n",
        "\n",
        "'''\n",
        "# Maze-3\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTb7ey-hiSnN"
      },
      "source": [
        "## Flatten Q-Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "DzvhXuTyiQnI",
        "outputId": "a96fd3da-955f-4ec0-f43a-c7606c0e836a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Flattened Q-table:\n",
            "[0.0, 0.0, 0.0, -8.038707105143146, -8.082612249219368, -8.075357976574818, 0.0, 0.0, 0.0, -6.647911287348904, -8.350614717222712, -8.359131172256962, 0.0, 0.0, 0.0, -8.401727003925874, -7.051792274204917, -8.407046054870735, -8.05865436530638, -8.055914330703747, -7.195154863191697, -8.159045656801942, -8.353843068419978, -8.358464332980923]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nFlattened Q-table (Maze-2):\\n[-0.14567542786524684, 0.028992119894766844, -0.2658059392757915, 15.500593710459835, -0.15679, -0.5751383360655641, -0.5, -0.7610600150158306, 19.256544264254092, 16.330889837828664, -2.594840781380889, -2.474224227054556, -0.852180077055561, -0.7006457235470309, 12.950534339413846, -2.2842125693118476, -2.776785077874974, -2.6859971955040907, -1.6150456834794744, -1.8485000844551536, 12.096579828480882, -2.7116605133971876, -3.133167873327339, -3.182911142097555]\\n'"
            ]
          },
          "execution_count": 167,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Flatten the Q-table for copying to Arduino code\n",
        "flattened_q_values = q_values.flatten()\n",
        "\n",
        "# Print the flattened Q-table\n",
        "print(\"Flattened Q-table:\")\n",
        "print(list(flattened_q_values))\n",
        "\n",
        "'''\n",
        "Flattened Q-table (Maze-2):\n",
        "[-0.14567542786524684, 0.028992119894766844, -0.2658059392757915, 15.500593710459835, -0.15679, -0.5751383360655641, -0.5, -0.7610600150158306, 19.256544264254092, 16.330889837828664, -2.594840781380889, -2.474224227054556, -0.852180077055561, -0.7006457235470309, 12.950534339413846, -2.2842125693118476, -2.776785077874974, -2.6859971955040907, -1.6150456834794744, -1.8485000844551536, 12.096579828480882, -2.7116605133971876, -3.133167873327339, -3.182911142097555]\n",
        "\n",
        "Flattened Q-table (Maze-3): obstacle avoidance\n",
        "[0.0, 0.0, 0.0, -8.038707105143146, -8.082612249219368, -8.075357976574818, 0.0, 0.0, 0.0, -6.647911287348904, -8.350614717222712, -8.359131172256962, 0.0, 0.0, 0.0, -8.401727003925874, -7.051792274204917, -8.407046054870735, -8.05865436530638, -8.055914330703747, -7.195154863191697, -8.159045656801942, -8.353843068419978, -8.358464332980923]\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pRnQC1ei1kO",
        "outputId": "07a6ec5b-b2cb-4a09-a120-407f6580c8c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-0.14567542786524684,\n",
              " 0.028992119894766844,\n",
              " -0.2658059392757915,\n",
              " 15.500593710459835,\n",
              " -0.15679,\n",
              " -0.5751383360655641,\n",
              " -0.5,\n",
              " -0.7610600150158306,\n",
              " 19.256544264254092,\n",
              " 16.330889837828664,\n",
              " -2.594840781380889,\n",
              " -2.474224227054556,\n",
              " -0.852180077055561,\n",
              " -0.7006457235470309,\n",
              " 12.950534339413846,\n",
              " -2.2842125693118476,\n",
              " -2.776785077874974,\n",
              " -2.6859971955040907,\n",
              " -1.6150456834794744,\n",
              " -1.8485000844551536,\n",
              " 12.096579828480882,\n",
              " -2.7116605133971876,\n",
              " -3.133167873327339,\n",
              " -3.182911142097555]"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f=[-0.14567542786524684, 0.028992119894766844, -0.2658059392757915, 15.500593710459835, -0.15679, -0.5751383360655641, -0.5, -0.7610600150158306, 19.256544264254092, 16.330889837828664, -2.594840781380889, -2.474224227054556, -0.852180077055561, -0.7006457235470309, 12.950534339413846, -2.2842125693118476, -2.776785077874974, -2.6859971955040907, -1.6150456834794744, -1.8485000844551536, 12.096579828480882, -2.7116605133971876, -3.133167873327339, -3.182911142097555]\n",
        "f"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZ1QENCug4Ca"
      },
      "source": [
        "## Experiment: Type-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovNYu_rZDNfM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define the maze\n",
        "maze = np.array([\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1],\n",
        "    [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1],\n",
        "    [1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1],\n",
        "    [1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1],\n",
        "    [1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1],\n",
        "    [1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1],\n",
        "    [1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1],\n",
        "    [1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
        "    [1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
        "    [1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
        "    [1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
        "    [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
        "])\n",
        "\n",
        "# Define the Q-network\n",
        "class QNetwork(tf.keras.Model):\n",
        "    def __init__(self, state_size, action_size):\n",
        "        super(QNetwork, self).__init__()\n",
        "        self.dense1 = tf.keras.layers.Dense(32, activation='relu', input_shape=(state_size,))\n",
        "        self.dense2 = tf.keras.layers.Dense(32, activation='relu')\n",
        "        self.output_layer = tf.keras.layers.Dense(action_size, activation='linear')\n",
        "\n",
        "    def call(self, state):\n",
        "        x = self.dense1(state)\n",
        "        x = self.dense2(x)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "# Hyperparameters\n",
        "state_size = 3  # [0, 0, 1]\n",
        "action_size = 3  # 4 possible actions: left, right, up, down\n",
        "learning_rate = 0.001\n",
        "discount_factor = 0.95\n",
        "\n",
        "# Instantiate the Q-network\n",
        "model = QNetwork(state_size, action_size)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='mse')\n",
        "\n",
        "# Q-learning training loop\n",
        "epochs = 1000\n",
        "for epoch in range(epochs):\n",
        "    current_state = [0, 0, 1]  # Start at the top-left corner of the maze\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "\n",
        "    while not done:\n",
        "        # Choose an action using epsilon-greedy strategy\n",
        "        epsilon = 0.1\n",
        "        if np.random.rand() < epsilon:\n",
        "            action = np.random.randint(action_size)\n",
        "        else:\n",
        "            q_values = model.predict(np.array([current_state]))\n",
        "            action = np.argmax(q_values)\n",
        "\n",
        "        # Take the chosen action and observe the next state and reward\n",
        "        next_state = np.copy(current_state)\n",
        "        if action == 0:  # Move left\n",
        "            next_state[0] = max(0, current_state[0] - 1)\n",
        "        elif action == 1:  # Move right\n",
        "            next_state[1] = min(1, current_state[1] + 1)\n",
        "        elif action == 2:  # Move up\n",
        "            next_state[2] = max(0, current_state[2] - 1)\n",
        "        elif action == 3:  # Move down\n",
        "            next_state[2] = min(1, current_state[2] + 1)\n",
        "\n",
        "        reward = -1 if maze[next_state[2], next_state[1]] == 0 else -100  # -1 for each step, -100 for hitting an obstacle\n",
        "\n",
        "        # Update the Q-value using the Bellman equation\n",
        "        q_values = model.predict(np.array([current_state]))\n",
        "        next_q_values = model.predict(np.array([next_state]))\n",
        "        q_values[0][action] = reward + discount_factor * np.max(next_q_values)\n",
        "\n",
        "        # Train the model on the current transition\n",
        "        model.train_on_batch(np.array([current_state]), q_values)\n",
        "\n",
        "        total_reward += reward\n",
        "        current_state = next_state\n",
        "\n",
        "        # Check if the episode is done\n",
        "        if maze[current_state[2], current_state[1]] == 1 or current_state == [1, 10, 1]:\n",
        "            done = True\n",
        "\n",
        "    print(f\"Epoch: {epoch + 1}, Total Reward: {total_reward}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_z5rgBE-iuo"
      },
      "source": [
        "## Experiment: Type-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPd9qOvV-YH1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Define the 2D maze\n",
        "maze = np.array([\n",
        "    [0, 0, 1, 0, 0],\n",
        "    [0, 0, 1, 0, 0],\n",
        "    [0, 0, 0, 0, 0],\n",
        "    [0, 1, 1, 0, 0],\n",
        "    [0, 0, 1, 0, 0]\n",
        "])\n",
        "\n",
        "# Define the maze\n",
        "maze = np.array([\n",
        "    [1, 1, 0, 1],\n",
        "    [1, 1, 0, 0],\n",
        "    [1, 1, 0, 1],\n",
        "    [1, 0, 0, 1],\n",
        "    [1, 0, 0, 0]\n",
        "])\n",
        "source = (1,3)\n",
        "destination = (4,3)\n",
        "\n",
        "# Define Q-learning parameters\n",
        "num_actions = 4  # Up, Down, Left, Right\n",
        "learning_rate = 0.1\n",
        "discount_factor = 0.9\n",
        "exploration_rate = 0.1\n",
        "exploration_rate_decay = 0.87\n",
        "num_episodes = 1000\n",
        "\n",
        "# Initialize Q-values\n",
        "q_values = np.zeros((maze.shape[0], maze.shape[1], num_actions))\n",
        "\n",
        "\n",
        "def display(maze, source, destination, current_position, path=None):\n",
        "    for i in range(len(maze)):\n",
        "        for j in range(len(maze[0])):\n",
        "            if (i, j) == source:\n",
        "                print('S', end=' ')\n",
        "            elif (i, j) == destination:\n",
        "                print('D', end=' ')\n",
        "            elif (i, j) == current_position:\n",
        "                print('C', end=' ')\n",
        "            elif path and (i, j) in path:\n",
        "                print('*', end=' ')  # Mark the path with '*'\n",
        "            elif maze[i][j] == 1:\n",
        "                print('#', end=' ')\n",
        "            else:\n",
        "                print('.', end=' ')\n",
        "        print()\n",
        "# Helper function to visualize the agent's path in the maze\n",
        "def visualize_path(path):\n",
        "    maze_copy = maze.copy()\n",
        "    for step in path:\n",
        "        maze_copy[step[0], step[1]] = 2  # Mark the path with 2\n",
        "    maze_copy[maze_copy == 1] = 9  # Mark walls with 9\n",
        "    maze_copy[maze_copy == 0] = 1  # Mark paths with 1\n",
        "    maze_copy[maze_copy == 2] = 0  # Mark the agent's path with 0\n",
        "\n",
        "    plt.imshow(maze_copy, cmap='viridis', origin='upper')\n",
        "    plt.show()\n",
        "\n",
        "# Q-learning algorithm\n",
        "for episode in range(num_episodes):\n",
        "    # state = (0, 0)  # Starting position\n",
        "    state=source\n",
        "    path = [state]\n",
        "\n",
        "    # while state != (maze.shape[0] - 1, maze.shape[1] - 1):  # Continue until reaching the goal\n",
        "    while state != destination:\n",
        "        # Choose an action using epsilon-greedy strategy\n",
        "        if np.random.rand() < exploration_rate:\n",
        "            action = np.random.choice(num_actions)\n",
        "        else:\n",
        "            action = np.argmax(q_values[state[0], state[1]])\n",
        "\n",
        "        # Perform the chosen action\n",
        "        if action == 0 and state[0] > 0:\n",
        "            new_state = (state[0] - 1, state[1])\n",
        "        elif action == 1 and state[0] < maze.shape[0] - 1:\n",
        "            new_state = (state[0] + 1, state[1])\n",
        "        elif action == 2 and state[1] > 0:\n",
        "            new_state = (state[0], state[1] - 1)\n",
        "        elif action == 3 and state[1] < maze.shape[1] - 1:\n",
        "            new_state = (state[0], state[1] + 1)\n",
        "        else:\n",
        "            new_state = state\n",
        "\n",
        "        # Update Q-value using the Bellman equation\n",
        "        reward = -1 if maze[new_state[0], new_state[1]] == 0 else -5  # Penalize hitting a wall\n",
        "        q_values[state[0], state[1], action] += learning_rate * (\n",
        "                reward + discount_factor * np.max(q_values[new_state[0], new_state[1]]) -\n",
        "                q_values[state[0], state[1], action])\n",
        "\n",
        "        # Move to the new state\n",
        "        state = new_state\n",
        "        path.append(state)\n",
        "        clear_output()\n",
        "\n",
        "    exploration_rate_decay *= exploration_rate_decay\n",
        "    if episode % 100 == 0:\n",
        "        display(maze=maze, path=path, source = (0,0), destination= (maze.shape[0] - 1, maze.shape[1] - 1), current_position=(maze.shape[0] - 1, maze.shape[1] - 1))\n",
        "\n",
        "print(\"Training complete!\")\n",
        "# visualize_path(path)\n",
        "display(maze=maze, path=path, source = (0,0), destination= (maze.shape[0] - 1, maze.shape[1] - 1), current_position=(maze.shape[0] - 1, maze.shape[1] - 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOe6uazE-dZu"
      },
      "source": [
        "## Using This trained Q network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLTCx4Vy-bdb"
      },
      "outputs": [],
      "source": [
        "source = (1,3)\n",
        "destination = (4,3)\n",
        "state = source\n",
        "path=[]\n",
        "while state != destination:\n",
        "    action = np.argmax(q_values[state[0], state[1]])\n",
        "    # Perform the chosen action\n",
        "    if action == 0 and state[0] > 0:\n",
        "        new_state = (state[0] - 1, state[1])\n",
        "    elif action == 1 and state[0] < maze.shape[0] - 1:\n",
        "        new_state = (state[0] + 1, state[1])\n",
        "    elif action == 2 and state[1] > 0:\n",
        "        new_state = (state[0], state[1] - 1)\n",
        "    elif action == 3 and state[1] < maze.shape[1] - 1:\n",
        "        new_state = (state[0], state[1] + 1)\n",
        "    else:\n",
        "        new_state = state\n",
        "    # Move to the new state\n",
        "    state = new_state\n",
        "    path.append(state)\n",
        "display(maze=maze, path=path, source = (0,0), destination= (maze.shape[0] - 1, maze.shape[1] - 1), current_position=(maze.shape[0] - 1, maze.shape[1] - 1))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
