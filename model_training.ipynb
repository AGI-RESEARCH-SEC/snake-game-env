{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqDkcTYwKFYu"
      },
      "source": [
        "# Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-giJIPtKRiL",
        "outputId": "383948b6-5359-4ef1-a4ed-f44f1702940d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/major-project/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdlHU0B2StU_",
        "outputId": "893fbf28-bf8f-479b-999f-8a9f91c8ab3a"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/major-project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8LEZeRHKFYz",
        "outputId": "6a8f6fbb-e568-471b-aaa5-646009a938f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.5, 0.52, 0.07511078841290904, 'down'],\n",
              " [0.52, 0.5, 0.23082908433171143, 'right'],\n",
              " [0.52, 0.5, 0.19554467028633868, 'right'],\n",
              " [0.5, 0.52, 0.47832986591579574, 'down'],\n",
              " [0.48, 0.5, 0.6736748727910522, 'left'],\n",
              " [0.5, 0.52, 0.07511078841290904, 'down'],\n",
              " [0.52, 0.5, 0.5069591830779546, 'right'],\n",
              " [0.52, 0.5, 0.313711827098512, 'right'],\n",
              " [0.48, 0.5, 0.6008863073032723, 'left'],\n",
              " [0.52, 0.5, 0.43725117539803654, 'right']]"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "import random\n",
        "import json\n",
        "import os\n",
        "\n",
        "def load_data():\n",
        "    if os.path.exists('fixed_destination.json'):\n",
        "      with open('fixed_destination.json', 'r') as f:\n",
        "        d = json.load(f)\n",
        "    elif os.path.exists('/content/drive/MyDrive/Colab Notebooks/major-project/fixed_destination.json'):\n",
        "        with open('/content/drive/MyDrive/Colab Notebooks/major-project/fixed_destination.json', 'r') as f:\n",
        "          d = json.load(f)\n",
        "    else:\n",
        "      raise Exception(\"data file does not exist\")\n",
        "\n",
        "    maze = d['maze']\n",
        "    data = d['data']\n",
        "    '''\n",
        "    model data is 2D list\n",
        "    inner dimension representing each data item: [0.52, 0.5, 0.1522936964597336, 'right']\n",
        "    '''\n",
        "    # shuffle data\n",
        "    random.shuffle(data)\n",
        "    data[:10]\n",
        "    return data\n",
        "\n",
        "data = load_data()\n",
        "data[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx7usmmBKFY2"
      },
      "source": [
        "## Training the model:\n",
        "* each data item is value like: [0.5, 0.52, 0.02503692947096968, 'down']\n",
        "* first two values represent vectorized co-ordinates\n",
        "* third value represent distance between current location and destination\n",
        "* last value represent label for model output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model1: LogisticRegression"
      ],
      "metadata": {
        "id": "g2cPcC0tRdtR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eY8JtYXjKFY3",
        "outputId": "6c0d43ae-96eb-4bc6-8390-eb691f455909"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9954219142455065\n",
            "Prediction: ['right']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# # Assuming your data is a list of lists\n",
        "# # Each data item is of the form: [x1, x2, distance, label]\n",
        "# # Example data\n",
        "# data = [\n",
        "#     [0.5, 0.52, 0.02503692947096968, 'down'],\n",
        "#     # Add more data items here\n",
        "# ]\n",
        "\n",
        "# Extract features (first three values) and labels\n",
        "X = np.array([item[:3] for item in data])\n",
        "y = np.array([item[3] for item in data])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Example usage to predict a new instance\n",
        "new_instance = np.array([0.6, 0.48, 0.030012, 'up'][:3])\n",
        "prediction = model.predict([new_instance])\n",
        "print(f\"Prediction: {prediction}\")\n",
        "\n",
        "# Save the model\n",
        "with open('logistic_regression_model.pkl','wb') as f:\n",
        "    pickle.dump(model, f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the model\n",
        "import pickle\n",
        "with open(\"logistic_regression_model.pkl\",'rb') as f:\n",
        "  loaded_model = pickle.load(f)\n",
        "\n",
        "# Example usage to predict a new instance\n",
        "new_instance = np.array([0.6, 0.48, 0.030012, 'up'][:3])\n",
        "prediction = loaded_model.predict([new_instance])\n",
        "print(f\"Prediction: {prediction}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSok2ePqSf2m",
        "outputId": "46afc6a0-14ad-4b58-d809-bde209db5248"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: ['right']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model2: DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "DHQErqjRRs8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Assuming your data is a list of lists\n",
        "# Each data item is of the form: [x1, x2, distance, label]\n",
        "data = load_data()\n",
        "# # Example data\n",
        "# data = [\n",
        "#     [0.5, 0.52, 0.02503692947096968, 'down'],\n",
        "#     # Add more data items here\n",
        "# ]\n",
        "\n",
        "# Extract features (first three values) and labels\n",
        "X = np.array([item[:3] for item in data])\n",
        "y = np.array([item[3] for item in data])\n",
        "\n",
        "# Convert string labels to numeric values\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree model\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Example usage to predict a new instance\n",
        "new_instance = np.array([[0.6, 0.48, 0.030012, 'up']])\n",
        "# Convert string label to numeric value\n",
        "new_instance[:, 3] = label_encoder.transform(new_instance[:, 3])\n",
        "prediction = model.predict(new_instance[:, :3])\n",
        "print(f\"Prediction: {prediction}\")\n",
        "\n",
        "# Save the model\n",
        "with open(\"decision_tree_model.pkl\",'wb') as f:\n",
        "  pickle.dump(model, f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUKOoY_TMXqY",
        "outputId": "54b29b4a-d34e-4175-bbc8-400ee631104f"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Prediction: [2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the model\n",
        "import pickle\n",
        "with open(\"decision_tree_model.pkl\",'rb') as f:\n",
        "  loaded_model = pickle.load(f)\n",
        "\n",
        "# Example usage to predict a new instance\n",
        "new_instance = np.array([0.6, 0.48, 0.030012, 'up'][:3])\n",
        "prediction = loaded_model.predict([new_instance])\n",
        "print(f\"Prediction: {prediction}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Euw5SjWiNkYt",
        "outputId": "a24e99dc-0d8f-4c8e-8e80-a3ec071f190d"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: [2]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "machine_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}